<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction">
  <meta property="og:title" content="MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction">
  <meta property="og:description" content="MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction">
  <meta property="og:image" content="https://shape-of-motion.github.io/static/images/open_graph.png">
  <meta property="twitter:title" content="MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction">
  <meta property="twitter:description" content="MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction">
  <meta property="twitter:image" content="https://shape-of-motion.github.io/static/images/open_graph.png">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="4D reconstruction, Dynamic Reconstruction, 3D Tracking, Long-Range Motion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction</title>
  <!-- <title>Generalizable Motion Segmentation with 3D Spatial-Temporal Information Priori-Guided</title> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- <script src="./static/js/lqm.js"></script> -->
  <script src="./static/js/video_comparison.js" defer></script>

  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ¬</text></svg>">

</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title">MuBe4D: A Mutual Benefit framework for Generalizable Motion Segmentation and Geometry-First 4D Reconstruction</h1>
            <!-- <h3 class="title is-1 publication-title">Anonymous Authors</h3> -->
            <!-- <h1 class="title is-4 publication-conference"> ICLR 2025 </h1> -->
            <div class="is-size-4 publication-authors">

<!--                <span class="author-block">
                Anonymous Authors</span> -->
              <span class="author-block">
                <h6>
                  <a href="" target="_blank">Shuo Zhang</a><sup>1</sup>,
                  <a href="" target="_blank">Bin Luo</a><sup>1</sup>,
                  <a href="" target="_blank">Wei Wang</a><sup>1&dagger;</sup>,
                  <a href="" target="_blank">Chenjie Wang</a><sup>2&dagger;</sup>,
                  <!-- <a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu</a><sup>2*</sup>,
                  <a href="https://jiepengwang.github.io/" target="_blank">Jiepeng Wang</a><sup>2</sup>,
                  <a href="" target="_blank">Xianqiang Lyv</a><sup>1</sup>,<br>
                  <a href="https://quartz-khaan-c6f.notion.site/Peng-Wang-0ab0a2521ecf40f5836581770c14219c" target="_blank">Peng Wang</a><sup>2</sup>,
                  <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html" target="_blank">Wenping Wang</a><sup>3</sup>,
                  <a href="" target="_blank">Junhui Hou</a><sup>1&dagger;</sup> -->
                </h6>
              </span>

            </div>
            <div class="is-size-5 publication-authors">
              <p>
                <sup>1</sup>Wuhan University &nbsp;&nbsp;
                <sup>1</sup>Hefei Comprehensive National Science Center &nbsp;&nbsp;
                <!-- <sup>2</sup>The University of Hong Kong&nbsp;&nbsp;&nbsp;&nbsp;
                <sup>3</sup>Texas A&M University&nbsp;&nbsp;&nbsp;&nbsp; -->
                <br>
                <!-- <sup>*</sup> Contribute equally. &nbsp;&nbsp; -->
                <sup>&dagger;</sup>Corresponding author. &nbsp;&nbsp;
              </p>
            </div>

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

    <!-- <section class="section">
    <div class="container is-max-desktop">
      <video id="teaser" width="100%" playsinline  autoplay loop muted>
        <source src="static/videos/teaser.mp4" type="video/mp4" />
      </video>
      <script>
        document.getElementById('teaser').play();
      </script>
    </div>
  </section> -->

  <!-- resutl on DyNeRF dataset -->
  <!-- resutl on DyNeRF dataset -->
  <!-- resutl on DyNeRF dataset -->
  <!-- resutl on DyNeRF dataset -->
  <section>
    <!-- </div> -->

    <div class="container is-max-desktop">
      <!-- <h2 class="title is-4">Results on DyNeRF dataset</h2> -->
      <!-- <p>
          Here we display results of our MoDGS On DyNeRF dataset. <br><br>
          Change the scene by clicking the button below:
        </p> -->
        <!-- <br><br>
        <br><br> -->
      
 
    <!-- <h2 class="title is-3">4D Renconstruction</h2> -->
  </div>
    <!-- <section class="hero is-light is-small"> -->
    <div class="hero-body">
      <div id="results-carousel" class="carousel results-carousel">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <!-- <div class="container"> -->
        <!-- <div class="item item-steve video-grid">
          <div class="video-description0">Ours</div>
          <div class="video-description1">Align3R</div> -->
          <!-- <div class="video-description2">estimated monocular depth</div>
          <div class="video-description3">rendered depth</div> -->
        <!-- </div> -->


          <!-- <div class="video-description0">input video</div> -->
          <!-- <video poster="" id="steve gt_rgb" autoplay muted loop playsinline width="60%">
            <source src="static/bonn_crowd3.mp4" type="video/mp4">
          </video> -->
        <div class="item item-steve video-grid">
            <div class="video-item">
              <div class="video-title">Align3R</div>
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline>
                <source src="static/video/cam_bonn_crowd3_Align3R.mp4" type="video/mp4">
              </video>
            </div>
            <div class="video-item">
              <div class="video-title">Ours</div>
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline>
                <source src="static/video/cam_bonn_crowd3.mp4" type="video/mp4">
              </video>
            </div>
        </div>
        <div class="item item-steve video-grid">
            <div class="video-item">
              <div class="video-title">Align3R</div>
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline>
                <source src="static/video/cam_bonn_ballon2_Align3R.mp4" type="video/mp4">
              </video>
            </div>
            <div class="video-item">
              <div class="video-title">Ours</div>
              <video poster="" id="steve gt_rgb" autoplay muted loop playsinline>
                <source src="static/video/cam_bonn_ballon2.mp4" type="video/mp4">
              </video>
            </div>
        </div>
          <!-- <div id="video-grid">
            <video poster="" id="steve gt_rgb" autoplay muted loop playsinline width="60%">
              <source src="static/bonn_crowd3.mp4" type="video/mp4">
            </video>
            <video poster="" id="steve gt_rgb" autoplay muted loop playsinline width="60%">
              <source src="static/bonn_crowd3.mp4" type="video/mp4">
            </video>
            <video poster="" id="steve gt_rgb" autoplay muted loop playsinline width="60%">
              <source src="static/bonn_crowd3.mp4" type="video/mp4">
            </video> -->
        </div>



      </div>

    </div>
    </div>
  </section>


  <div class="container is-max-desktop">
    <h2 style="text-align: center;" class="is-size-5">A unified framework for mutual reinforcement of motion and geometry, </h2>
    <h2 style="text-align: center;" class="is-size-5">Zero-shot motion segmentation with 3D spatio-temporal information priori-guided, </h2>
    <h2 style="text-align: center;" class="is-size-5">Enhanced 4D renconstruction pipeline</h2>
    <img src="static/img/fig_contrib.png" alt="Image description" style="display: block; margin: auto;">
    <br><br>
    <h2 class="title is-3">Qulitative Results of Motion Segmentation</h2>
    <img src="static/img/fig_seg_show.png" alt="Image description" style="display: block; margin: auto;">
  </div>






  <!-- <br>
  <br>
  <br>
  <br>
  <br> -->

      <!-- Abstract -->
  <!-- Abstract -->
  <!-- Abstract -->
  <!-- <section class="section"> -->
    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The estimation of both motion and geometry from dynamic scenes is an open and underconstrained problem in computer vision. Constrained by the limited availability of co-labeled data, current end-to-end methods consider motion segmentation and geometry estimation as two independent tasks. Existing approaches typically use motion segmentation to facilitate geometric alignment. However, geometry estimation also offers valuable information that can enhance motion segmentation.
          </p>
          <p>
            This paper proposes a framework that mutually benefits zero-shot motion segmentation and consistent geometric reconstruction. Specifically, 3D spatio-temporal priors are extracted from a geometry-first 4D reconstruction model to guide generalizable motion segmentation. A Dual-Dimension Multi-path Information Fusion (D$^2$MIF) module is designed to fuse complementary 3D and 2D information at multiple scales through a recursive refinement mechanism, thereby improving zero-shot segmentation in complex dynamic scenes include background distraction and object articulations. Subsequently, the refined motion segmentation mask is utilized to more accurately separate the dynamic foreground from the static background during alignment, thus improving the geometric consistency of the 4D reconstruction. The resulting framework produces an integrated output for several downstream video-specific tasks while maintaining efficiency. Experimental results validate the mutual benefits of the proposed framework and its superiority in downstream 4D reconstruction tasks. The generalizability of the motion segmentation model is confirmed through a series of zero-shot evaluations.
          </p>
        </div>
      </div>
    </section>
  
    <!-- <section class="section" id="abstract">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column">
            <iframe width="960" height="540" src="https://www.youtube.com/embed/oBN3p716c_k?si=5r9EEMeMLzn6Is1l" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </section> -->

  <section class="section">
    <div class="container is-max-desktop">

      <h2 class="title is-3">Method</h2>
      <div class="container is-max-desktop">
        <img src="static/img/fig_method.png" alt="Image description" style="display: block; margin: auto;">
        <p>
          <strong>Overview.</strong> Overview of the 3D spatio-temporal information priori-guided motion segmentation framework. 
          We feed time-dependent image pairs into the 4D reconstruction model to extract 3D spatio-temporal priors. 
          The D^2MIF (Dual-Dimension Multi-path Information Fusion) module then integrates 2D and 3D spatio-temporal information 
          from multiple paths and recursively fuses spatio-temporal features to generate dynamic segmentation masks. 
          Additionally, our motion segmentation model is incorporated as a plug-and-play sub-module within the existing 4D scene reconstruction 
          pipeline, thereby enhancing reconstruction quality through the use of refined dynamic mask.
        </p>
      </div>
      <br><br>
      <div class="container is-max-desktop">
        <img src="static/img/fig_recon_pipeline.png" alt="Image description" style="display: block; margin: auto;">
        <p>
          <strong>Schematic of enhanced 4D renconstruction pipeline.</strong>
          	We construct video graphs from time-continuous video frames using 
          a sliding window approach to form image pairs. For each pair, we predict motion segmentation masks and local pointmaps (top). 
          During batch optimization, an initial globally aligned pointmaps is generated using a Minimum Spanning Tree and rigid registration, 
          followed by iterative optimization via first-order gradient descent (left bottom). 
          Additionally, we optimize the keyframe strategy to enhance global scale consistency in hierarchical optimization (right bottom).
        </p>
      </div>
      <br><br>
    </div>
  </section>





  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This webpage is based on the project page for <a href="https://https://modgs.github.io/">MoDGS</a>, <a href="https://nerf-casting.github.io/">NeRF-Casting</a>,
              <a href="https://camp-nerf.github.io">CamP</a> and <a href="https://nerfies.github.io/">Nerfies</a>. The
              video
              comparison tool is from the <a href="https://dorverbin.github.io/refnerf/index.html">Ref-NeRF</a>
              project.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>
